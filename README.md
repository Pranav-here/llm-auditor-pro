# AI Knowledge AuditorÂ Pro

A lightweight **Streamlit** application for objectively assessing whether an AIâ€‘generated answer is supported by evidence found in a reference PDF.

ğŸ”— **Live Demo**: [https://llm-auditor-pro.streamlit.app](https://llm-auditor-pro.streamlit.app)

---

## 1Â Â Project Scope

The project implements an endâ€‘toâ€‘end verification pipeline that
1. **Ingests PDF documents** and performs sentenceâ€‘aware chunking;
2. **Builds a FAISS vector index** using `allâ€‘mpnetâ€‘baseâ€‘v2` sentence embeddings;
3. **Retrieves candidate passages** via a hybrid query that blends the userâ€™s question and the modelâ€™s answer;
4. **Ranks passages** with a crossâ€‘encoder similarity check;
5. **Calculates a multiâ€‘factor trust score** using four signals:
   - Semantic similarity
   - Textual overlap (nâ€‘gram, keyphrase, sequence ratio)
   - Namedâ€‘entity alignment (spaCy NER)
   - Basic factual consistency (numeric/context agreement)
6. **Explains the verdict** by highlighting matching sentences and scoring components;
7. **Aggregates results** in a singleâ€‘audit view, a batch processor, and a live analytics dashboard.

All computational steps run locally; no external services are required once the models are downloaded.

---

## 2Â Â Key Features (Implemented)

| Module | Description |
| ------ | ----------- |
| **Document Loader** | Extracts text from PDFs using *PyMuPDF* (fitz) and cleans layout artifacts. |
| **Smart Chunker** | Splits text at sentence boundaries; retains configurable overlap for context preservation. |
| **Vector Store** | Normalised cosineâ€‘similarity index built with **FAISS**; enables millisecond retrieval. |
| **Hybrid Search** | Weights the question (70Â %) and the answer (30Â %) to form a single query vector. |
| **Auditor Core** | Combines retrieval, scoring, explanation generation, and sentence highlighting. |
| **BatchÂ Processor** | Processes CSV files of Q&A pairs concurrently; outputs a Markdown or CSV report. |
| **Streamlit UI** | Wideâ€‘layout interface with tabbed navigation, Plotly charts, and adjustable thresholds. |

---

## 3Â Â SystemÂ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PDF in   â”‚â”€â”€â–¶â”€â”€â”‚   Chunker &   â”‚â”€â”€â–¶â”€â”€â”‚   Embeddings   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  EntityÂ NER   â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
        â–¼                                         â–¼
   FAISSÂ Index  â—€â”€â”€ Hybrid Search â—€â”€â”€  QuestionÂ +Â Answer
        â”‚                                         â”‚
        â–¼                                         â–¼
Candidate Passages â”€â–¶ Scoring & Highlighting â”€â–¶ Trust Report
```

---

## 4Â Â Usage

```bash
# Launch the application
streamlit run app.py
```

1. Upload a PDF (â‰¤Â 200Â MB).
2. Enter the question posed to the LLM and the modelâ€™s answer.
3. Review the trust score, highlighted evidence, and factor breakdown.
4. (Optional) Switch to **Batch Processing** to audit many Q&A pairs at once.

---

## 5Â Â Example Output

<!-- Replace with annotated screenshot or animated GIF illustrating a single audit. -->
*(See the `app test/` folder for working examples and benchmark screenshots.)*

---

## 6Â Â Performance Snapshot *(local workstation, RTXÂ 3060)*

| Task | Size | Time |
| ---- | ---- | ---- |
| Index build | 200â€‘page PDF |Â â‰ˆÂ 15Â s |
| Single audit | avg. 500â€¯tokens answer |Â <Â 4Â s |
| Batch (100 pairs) | same doc |Â â‰ˆÂ 70Â s |

---

## 7Â Â Roadmap

- [ ] Crossâ€‘encoder factuality classifier (planned)
- [ ] Hugging FaceÂ Spaces demo (planned)
- [ ] Pluggable vector databases (Milvus / Qdrant)

---

## 8Â Â License

Released under the MITÂ License.

---

## 9Â Â Acknowledgements

Built with **Sentenceâ€‘Transformers**, **FAISS**, **spaCy**, **PyMuPDF**, **Plotly**, and **Streamlit**.


